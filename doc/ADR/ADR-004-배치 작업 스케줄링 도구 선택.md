# ADR-004: 배치 작업 스케줄링 도구 선택

**Status**: Accepted  
**Date**: 2025-07-03

---

## 1. Context (배경 및 문제 정의)
프로젝트에서 대용량 데이터 처리 및 정기적 ETL, 데이터 파이프라인을 안정적으로 운영하기 위해 배치 작업 스케줄링 도구가 필요합니다.  
효율적인 작업 관리, 의존성 처리, 모니터링 및 장애 대응이 가능한 솔루션을 선정해야 합니다.

## 2. Decision (내린 결정)
우리는 Apache Airflow를 배치 스케줄링 도구로 사용하기로 결정하였습니다.

## 3. Alternatives Considered (고려했던 대안들)
1. **Apache Airflow** ✅ 선택
   - 장점: 워크플로우를 코드(DAG)로 정의해 유연한 의존성 관리 가능  
     풍부한 커넥터와 플러그인으로 확장성 우수  
     Web UI를 통한 시각적 모니터링과 스케줄 관리  
     Backfill 기능으로 과거 데이터 처리에 유리
   - 단점: 초기 설정과 운영 복잡도 있음, 리소스 소모 비교적 큼

2. **AWS Step Functions**
   - 장점: AWS 서비스와 긴밀한 통합, 서버리스 관리형 서비스  
     시각적 워크플로우 설계 및 자동 확장 지원
   - 단점: 복잡한 파이프라인 구현 시 제한적일 수 있고, AWS 종속성 존재

3. **Cron + Custom Scripts**
   - 장점: 간단한 작업에 적합, 설정 및 실행이 쉬움
   - 단점: 의존성 관리, 장애 복구, 재처리 등 기능이 부족하며 유지보수 어려움

## 4. Rationale (결정의 이유)
- 프로젝트 구조상 과거의 블록 데이터를 다시 처리해야 하는 **Backfill 기능이 핵심 요건**이었음
- DAG 기반 워크플로우 정의를 통해 복잡한 의존성과 파이프라인을 코드로 관리할 수 있음
- Glue, S3, Redshift 등과의 연동도 Airflow Operator나 Hook을 통해 원활하게 가능
- 팀 내 Python 중심 개발 환경과도 잘 맞고, 커뮤니티 자료가 풍부해 학습 및 운영에 유리

## 5. Consequences (영향 및 결과)
- Airflow의 설치, 운영, 워커 분리 등 인프라 구성에 대한 이해가 필요하며, 초기 진입 장벽이 있음
  (ECS, EC2, MWAA, Kubernetes 등 배포 방식 선택 고려 필요)
- DAG 작성 및 테스트, 모니터링 체계 구성 등의 학습과 운영 부담이 증가함
- 하지만 유연성과 자동화, 장애 복구 능력을 갖춘 안정적인 워크플로우 관리가 가능해짐

## 6. Related Decisions (관련 ADR 문서)
- ADR-001: AWS 기반 클라우드 인프라 사용
- ADR-002: 데이터 처리 방식 선택
- ADR-003: 데이터 웨어하우스 선택

## 7. References (참고 자료)
- [Apache Airflow 공식 문서](https://airflow.apache.org/docs/)
- [AWS Step Functions 공식 문서](https://docs.aws.amazon.com/step-functions/)